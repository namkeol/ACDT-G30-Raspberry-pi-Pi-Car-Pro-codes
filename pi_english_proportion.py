import os
from datetime import datetime
import time
import threading
import re

import sounddevice as sd
import soundfile as sf
from openai import OpenAI

# --- OpenAI í´ë¼ì´ì–¸íŠ¸ ---
client = OpenAI()   # í™˜ê²½ë³€ìˆ˜ì— API KEY ì €ì¥í–ˆë‹¤ë©´ ê´„í˜¸ ë¹„ì›Œë‘ê¸°

# --- ì„¤ì • ---
SAVE_DIR = "/home/pi/recorded_voice"  # ë¼ì¦ˆë² ë¦¬íŒŒì´ ì €ì¥ ê²½ë¡œ
DURATION_SEC = 20
SAMPLE_RATE = 44100  # USB ë§ˆì´í¬ ì•ˆì „ ìƒ˜í”Œë ˆì´íŠ¸
CHANNELS = 1

# USB ë§ˆì´í¬ ì¥ì¹˜ ê³ ì •
MIC_INDEX = 0  # 'USB PnP Sound Device'

def countdown_timer(duration_sec: int, stop_event: threading.Event):
    """ë…¹ìŒ ì¤‘ ì‹¤ì‹œê°„ ì¹´ìš´íŠ¸ì—… í‘œì‹œ"""
    for sec in range(1, duration_sec + 1):
        if stop_event.is_set():
            break
        print(f"\râ±ï¸ ë…¹ìŒ ì§„í–‰ ì¤‘: {sec:02d} / {duration_sec:02d} ì´ˆ", end="")
        time.sleep(1)
    print()

def record_audio_to_wav() -> str:
    os.makedirs(SAVE_DIR, exist_ok=True)

    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    out_path = os.path.join(SAVE_DIR, f"record_{ts}.wav")

    print("\n===================================")
    print("ğŸ¤ [ìƒíƒœ] ì¤€ë¹„ ì™„ë£Œ! 3ì´ˆ í›„ ë…¹ìŒ ì‹œì‘")
    print("===================================\n")
    time.sleep(3)

    print(f"ğŸ™ï¸ [ìƒíƒœ] ë…¹ìŒ ì‹œì‘!! (ì¥ì¹˜: {MIC_INDEX}, ìƒ˜í”Œë ˆì´íŠ¸: {SAMPLE_RATE})")

    audio = sd.rec(
        int(DURATION_SEC * SAMPLE_RATE),
        samplerate=SAMPLE_RATE,
        channels=CHANNELS,
        dtype="int16",
        device=MIC_INDEX
    )

    stop_event = threading.Event()
    timer_thread = threading.Thread(target=countdown_timer, args=(DURATION_SEC, stop_event))
    timer_thread.start()

    sd.wait()
    stop_event.set()
    timer_thread.join()

    print("\nğŸ›‘ [ìƒíƒœ] ë…¹ìŒ ì¢…ë£Œ!")
    print("ğŸ’¾ ì €ì¥ ì¤‘...")

    sf.write(out_path, audio, SAMPLE_RATE)
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {out_path}")

    return out_path

def analyze_english_ratio(text: str):
    """STT í…ìŠ¤íŠ¸ ì† ì˜ì–´ ë‹¨ì–´ ë¹„ìœ¨ ê³„ì‚°"""
    english_words = re.findall(r"[A-Za-z]+", text)
    all_words = re.findall(r"[A-Za-z0-9ê°€-í£]+", text)

    eng_count = len(english_words)
    total_count = len(all_words)

    ratio = (eng_count / total_count * 100) if total_count > 0 else 0

    print("\n===== ğŸ” ì˜ì–´ ë‹¨ì–´ ë¹„ìœ¨ ë¶„ì„ =====")
    print(f"ì˜ì–´ ë‹¨ì–´ ìˆ˜: {eng_count}")
    print(f"ì „ì²´ ë‹¨ì–´ ìˆ˜: {total_count}")
    print(f"ì˜ì–´ ë¹„ìœ¨: {ratio:.2f}%")
    print(f"ì˜ì–´ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸: {english_words}")
    print("================================")

    return ratio

def transcribe_audio(path: str):
    print("\nğŸ”„ [ìƒíƒœ] OpenAIì— ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜ ìš”ì²­ ì¤‘...")

    with open(path, "rb") as f:
        result = client.audio.transcriptions.create(
            file=f,
            model="gpt-4o-transcribe",
            response_format="json",
        )

    text = getattr(result, "text", "") or str(result)

    print("\n===== ğŸ“ ë³€í™˜ëœ í…ìŠ¤íŠ¸ =====")
    print(text)
    print("============================")

    # ì˜ì–´ ë¹„ìœ¨ ë¶„ì„ ì¶”ê°€
    analyze_english_ratio(text)

    return text

if __name__ == "__main__":
    wav_path = record_audio_to_wav()
    transcribe_audio(wav_path)
