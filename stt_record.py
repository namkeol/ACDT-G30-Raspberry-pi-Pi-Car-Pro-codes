import os
from datetime import datetime
import time
import threading

import sounddevice as sd
import soundfile as sf
from openai import OpenAI

# --- OpenAI í´ë¼ì´ì–¸íŠ¸ ---
client = OpenAI()   # í™˜ê²½ë³€ìˆ˜ì— API KEY ì €ì¥í–ˆë‹¤ë©´ ê´„í˜¸ ë¹„ì›Œë‘ê¸°

# --- ì„¤ì • ---
SAVE_DIR = r"C:\Users\ì´ë‚¨ê±¸(í•™êµ)\Desktop\recorded_voice"
DURATION_SEC = 20
SAMPLE_RATE = 16000
CHANNELS = 1

# USB ë§ˆì´í¬ ë²ˆí˜¸
USB_MIC_INDEX = 1    # "1 ë§ˆì´í¬(USB PnP Sound Device)"


def countdown_timer(duration_sec: int, stop_event: threading.Event):
    """ë…¹ìŒ ì¤‘ ì‹¤ì‹œê°„ ì¹´ìš´íŠ¸ì—… í‘œì‹œ"""
    for sec in range(1, duration_sec + 1):
        if stop_event.is_set():
            break
        print(f"\râ±ï¸ ë…¹ìŒ ì§„í–‰ ì¤‘: {sec:02d} / {duration_sec:02d} ì´ˆ", end="")
        time.sleep(1)
    print()  # ì¤„ë°”ê¿ˆ


def record_audio_to_wav() -> str:
    os.makedirs(SAVE_DIR, exist_ok=True)

    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    out_path = os.path.join(SAVE_DIR, f"record_{ts}.wav")

    print("\n===================================")
    print("ğŸ¤ [ìƒíƒœ] ì¤€ë¹„ ì™„ë£Œ! 3ì´ˆ í›„ ë…¹ìŒ ì‹œì‘")
    print("===================================\n")
    time.sleep(3)

    print("ğŸ™ï¸ [ìƒíƒœ] ë…¹ìŒ ì‹œì‘!!")

    # ë…¹ìŒ ì‹œì‘
    audio = sd.rec(
        int(DURATION_SEC * SAMPLE_RATE),
        samplerate=SAMPLE_RATE,
        channels=CHANNELS,
        dtype="int16",
        device=USB_MIC_INDEX
    )

    # ì¹´ìš´í„° ìŠ¤ë ˆë“œ ì‹œì‘
    stop_event = threading.Event()
    timer_thread = threading.Thread(target=countdown_timer, args=(DURATION_SEC, stop_event))
    timer_thread.start()

    # ë…¹ìŒ ì¢…ë£Œê¹Œì§€ ëŒ€ê¸°
    sd.wait()
    stop_event.set()
    timer_thread.join()

    print("\nğŸ›‘ [ìƒíƒœ] ë…¹ìŒ ì¢…ë£Œ!")
    print("ğŸ’¾ ì €ì¥ ì¤‘...")

    sf.write(out_path, audio, SAMPLE_RATE)
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {out_path}")

    return out_path


def transcribe_audio(path: str):
    print("\nğŸ”„ [ìƒíƒœ] OpenAIì— ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜ ìš”ì²­ ì¤‘...")

    with open(path, "rb") as f:
        result = client.audio.transcriptions.create(
            file=f,
            model="gpt-4o-transcribe",
            response_format="json",
        )

    text = getattr(result, "text", "") or str(result)

    print("\n===== ğŸ“ ë³€í™˜ëœ í…ìŠ¤íŠ¸ =====")
    print(text)
    print("============================")

    return text


if __name__ == "__main__":
    wav_path = record_audio_to_wav()
    transcribe_audio(wav_path)
